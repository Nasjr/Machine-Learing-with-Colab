{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_nlLW4Ps8xDedCsjnPrhRL_gKshLN-3S",
      "authorship_tag": "ABX9TyMHk7LGcKoDb4NP4Ga1OpOA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nasjr/Machine-Learing-with-Colab/blob/main/Data_Science_Project_ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LzKyeFrYYI9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from google.colab.patches import cv2_imshow \n",
        "from random import shuffle\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "dataset = '/content/drive/MyDrive/DataScience_Project/fulldata_resized (1).zip'\n",
        "\n",
        "with ZipFile(dataset, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAmskDB6ZfbN",
        "outputId": "6c3559b1-737f-43f9-e45d-dc6924cdb714"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset is extracted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path='/content/fulldata_resized'\n",
        "file_names_full=os.listdir(dataset_path)\n",
        "#print the first three file names\n",
        "print(file_names_full[0:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JtUzBK3WZfeN",
        "outputId": "1511c0df-4eb3-4421-b202-92eeff7d06c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['dog874.jpeg', 'chicken1468.jpeg', 'horse10.jpeg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reduce the size of data (deleted some images and eleminated some classes so that the size is trainable and don't consume memory) no need to run it again the data is already saved\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "fullpath='/content/fulldata_resized/'\n",
        "\n",
        "#Set a limit for deleting images\n",
        "count_dog=0\n",
        "cat_count=0\n",
        "buter_count=0\n",
        "horse_count=0\n",
        "cow_count=0\n",
        "chicken_count=0\n",
        "\n",
        "\n",
        "for i in range(len(file_names_full)):\n",
        "  if file_names_full[i][0:3]=='dog'and count_dog<1000:\n",
        "    try:\n",
        "      os.remove(fullpath+file_names_full[i])\n",
        "      count_dog+=1\n",
        "    except OSError as e:\n",
        "      # If it fails, inform the user.\n",
        "      print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "\n",
        "\n",
        "for i in range(len(file_names_full)):\n",
        "  if file_names_full[i][0:3]=='cat'and cat_count<950:\n",
        "    try:\n",
        "      os.remove(fullpath+file_names_full[i])\n",
        "      cat_count+=1\n",
        "    except OSError as e:\n",
        "      # If it fails, inform the user.\n",
        "      print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "\n",
        "\n",
        "\n",
        "#remove this class\n",
        "for i in range(len(file_names_full)):\n",
        "  if file_names_full[i][0:9]=='butterfly':\n",
        "    try:\n",
        "      os.remove(fullpath+file_names_full[i])\n",
        "    except OSError as e:\n",
        "      # If it fails, inform the user.\n",
        "      print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "\n",
        "\n",
        "for i in range(len(file_names_full)):\n",
        "  if file_names_full[i][0:5]=='horse'and horse_count<950:\n",
        "    try:\n",
        "      os.remove(fullpath+file_names_full[i])\n",
        "      horse_count+=1\n",
        "    except OSError as e:\n",
        "      # If it fails, inform the user.\n",
        "      print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "\n",
        "\n",
        "for i in range(len(file_names_full)):\n",
        "  if file_names_full[i][0:3]=='cow'and cow_count<850:\n",
        "    try:\n",
        "      os.remove(fullpath+file_names_full[i])\n",
        "      cow_count+=1\n",
        "    except OSError as e:\n",
        "      # If it fails, inform the user.\n",
        "      print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "\n",
        "#remove this class\n",
        "for i in range(len(file_names_full)):\n",
        "  if file_names_full[i][0:7]=='chicken':\n",
        "    try:\n",
        "      os.remove(fullpath+file_names_full[i])\n",
        "    except OSError as e:\n",
        "      # If it fails, inform the user.\n",
        "      print(\"Error: %s - %s.\" % (e.filename, e.strerror))\"\"\""
      ],
      "metadata": {
        "id": "xIphOwAi0OTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Categories\n",
        "\n",
        "**In this Dataset we have several Categories and we are going to show them below :**\n",
        "\n"
      ],
      "metadata": {
        "id": "4Su-T2-7lrdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check all the types after reducing the size of the data\n",
        "\"\"\"D_counts={'dog':0,'cat':0,\"butterfly\":0,\"horse\":0,'cow':0,'chicken':0,\"error\":0}\n",
        "for i in range(len(file_names_reduced)):\n",
        "    if file_names_reduced[i][0:3]=='dog':\n",
        "        D_counts['dog']+=1\n",
        "    elif file_names_reduced[i][0:3]=='cat':\n",
        "        D_counts['cat']+=1\n",
        "    elif file_names_reduced[i][0:9]=='butterfly':\n",
        "        D_counts['butterfly']+=1\n",
        "    elif file_names_reduced[i][0:5]=='horse':\n",
        "        D_counts['horse']+=1\n",
        "    elif file_names_reduced[i][0:3]=='cow':\n",
        "        D_counts['cow']+=1\n",
        "    elif file_names_reduced[i][0:7]=='chicken':\n",
        "        D_counts['chicken']+=1\n",
        "    else:\n",
        "        D_counts['error']+=1\n",
        "print(D_counts)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "ZYWeip5oZfgt",
        "outputId": "3fa71471-3fa9-4c93-c6f0-fc6d97eba8be"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'D_counts={\\'dog\\':0,\\'cat\\':0,\"butterfly\":0,\"horse\":0,\\'cow\\':0,\\'chicken\\':0,\"error\":0}\\nfor i in range(len(file_names_reduced)):\\n    if file_names_reduced[i][0:3]==\\'dog\\':\\n        D_counts[\\'dog\\']+=1\\n    elif file_names_reduced[i][0:3]==\\'cat\\':\\n        D_counts[\\'cat\\']+=1\\n    elif file_names_reduced[i][0:9]==\\'butterfly\\':\\n        D_counts[\\'butterfly\\']+=1\\n    elif file_names_reduced[i][0:5]==\\'horse\\':\\n        D_counts[\\'horse\\']+=1\\n    elif file_names_reduced[i][0:3]==\\'cow\\':\\n        D_counts[\\'cow\\']+=1\\n    elif file_names_reduced[i][0:7]==\\'chicken\\':\\n        D_counts[\\'chicken\\']+=1\\n    else:\\n        D_counts[\\'error\\']+=1\\nprint(D_counts)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As We see we have :**\n",
        "\n",
        "\n",
        "*   Dogs : 1775 image\n",
        "*   cats : 1668 image\n",
        "*   butterfly : 1496 image\n",
        "*   horse : 1686 image\n",
        "*   cow : 1566 image\n",
        "*   chicken : 1547 image\n",
        "\n",
        "**After reducing data we have:**\n",
        "\n",
        "\n",
        "\n",
        "*   dog: 755\n",
        "*   cat: 718\n",
        "*   butterfly: 0\n",
        "*   horse: 736\n",
        "*   cow: 716\n",
        "*   chicken: 0\n",
        "\n",
        "\n",
        "**Each Category Must be mapped to a number from (1 to n) where n is the number of categories :**\n",
        "\n",
        "\n",
        "*   Dogs --> 0\n",
        "*   cats --> 1\n",
        "*   horse --> 2\n",
        "*   cow --> 3\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-LFFbMRdmaRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This was made to resize the images the images are saved on drive no need to run it again\n",
        "\"\"\"resized_folder = '/content/image_resized_reduced/'\n",
        "image_directory = '/content/fulldata_resized/'\n",
        "\n",
        "\n",
        "for i in range(len(file_names_reduced)):\n",
        "  img_path = image_directory+file_names_reduced[i]\n",
        "\n",
        "  img = Image.open(img_path)\n",
        "  img = img.resize((224, 224))\n",
        "  img = img.convert('RGB')\n",
        "\n",
        "  newImgPath = resized_folder+file_names_reduced[i]\n",
        "  img.save(newImgPath)\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "V-bnnoQKBq36",
        "outputId": "25106096-0770-4f87-a787-d531ca710be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"resized_folder = '/content/image_resized_reduced/'\\nimage_directory = '/content/fulldata_resized/'\\n\\n\\nfor i in range(len(file_names_reduced)):\\n  img_path = image_directory+file_names_reduced[i]\\n\\n  img = Image.open(img_path)\\n  img = img.resize((224, 224))\\n  img = img.convert('RGB')\\n\\n  newImgPath = resized_folder+file_names_reduced[i]\\n  img.save(newImgPath)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#We need two lists one for the filenames and one for the labels\n",
        "file_names_resize_reduced=os.listdir('/content/image_resized_reduced')\n",
        "for i in range(5):\n",
        "  random.seed(4)\n",
        "  random.shuffle(file_names_resize_reduced)\n",
        "print('shffuled list: ',file_names_resize_reduced[0:10])\n",
        "\n",
        "\n",
        "labels=[]\n",
        "imgnames=[]\n",
        "\n",
        "for i in range(len(file_names_resize_reduced)):\n",
        "  \n",
        "  #Store the image names\n",
        "  imgnames.append(file_names_resize_reduced[i])\n",
        "  \n",
        "  #Store the labels of the images\n",
        "  if file_names_resize_reduced[i][0:3]=='dog':\n",
        "        labels.append(0)\n",
        "  elif file_names_resize_reduced[i][0:3]=='cat':\n",
        "        labels.append(1)\n",
        "  elif file_names_resize_reduced[i][0:9]=='butterfly':\n",
        "        labels.append(2)\n",
        "  elif file_names_resize_reduced[i][0:5]=='horse':\n",
        "        labels.append(2)\n",
        "  elif file_names_resize_reduced[i][0:3]=='cow':\n",
        "        labels.append(3)\n",
        "  elif file_names_resize_reduced[i][0:7]=='chicken':\n",
        "        labels.append(4)\n",
        "  else:\n",
        "        print('This is an error')\n",
        "\n",
        "print(imgnames[0:7])\n",
        "print(labels[0:7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0T_GetBZfjV",
        "outputId": "061a4b27-746f-4858-fb17-9309e92067d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shffuled list:  ['dog529.jpeg', 'cat622.jpeg', 'horse870.jpeg', 'cat63.jpeg', 'cat1208.jpeg', 'cat1230.jpeg', 'cat652.jpeg', 'horse464.jpeg', 'dog1647.jpeg', 'horse1289.jpeg']\n",
            "['dog529.jpeg', 'cat622.jpeg', 'horse870.jpeg', 'cat63.jpeg', 'cat1208.jpeg', 'cat1230.jpeg', 'cat652.jpeg']\n",
            "[0, 1, 2, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#After deleting classes of animals\n",
        "D_counts={'dog':0,'cat':0,\"butterfly\":0,\"horse\":0,'cow':0,'chicken':0,\"error\":0}\n",
        "for i in range(len(file_names_resize_reduced)):\n",
        "    if file_names_resize_reduced[i][0:3]=='dog':\n",
        "        D_counts['dog']+=1\n",
        "    elif file_names_resize_reduced[i][0:3]=='cat':\n",
        "        D_counts['cat']+=1\n",
        "    elif file_names_resize_reduced[i][0:9]=='butterfly':\n",
        "        D_counts['butterfly']+=1\n",
        "    elif file_names_resize_reduced[i][0:5]=='horse':\n",
        "        D_counts['horse']+=1\n",
        "    elif file_names_resize_reduced[i][0:3]=='cow':\n",
        "        D_counts['cow']+=1\n",
        "    elif file_names_resize_reduced[i][0:7]=='chicken':\n",
        "        D_counts['chicken']+=1\n",
        "    else:\n",
        "        D_counts['error']+=1\n",
        "print(D_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVUt6FkNERzc",
        "outputId": "232774a9-e8fc-40e8-f651-b2576b634213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dog': 755, 'cat': 718, 'butterfly': 0, 'horse': 736, 'cow': 716, 'chicken': 0, 'error': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import glob\n",
        "\n",
        "image_directory = '/content/image_resized_reduced/'\n",
        "\n",
        "\n",
        "files = []\n",
        "\n",
        "for name in file_names_resize_reduced:\n",
        "  files.append(image_directory+name)\n",
        "#check for file names\n",
        "print(files[0:3])\n",
        "\n",
        "\n",
        "#convert all images into a MD numpy array aka 'Tensor'\n",
        "all_images_array=np.asarray([cv2.imread(file) for file in files] )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thcNbhclZfl9",
        "outputId": "b9126e27-be71-4b2e-aee6-e1bd68e4c395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/image_resized_reduced/dog529.jpeg', '/content/image_resized_reduced/cat622.jpeg', '/content/image_resized_reduced/horse870.jpeg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(all_images_array.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j66wPIIUZfol",
        "outputId": "bab6596f-f044-4734-ef6c-d248c8bb0302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2925, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#shape the data into x and y variables for training and testing\n",
        "\n",
        "X=all_images_array\n",
        "y=np.asarray(labels)\n"
      ],
      "metadata": {
        "id": "cry3XxZfrfn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# It Is time to split our data into Training and testing Data for our model using (train_test_split) function :"
      ],
      "metadata": {
        "id": "zXeR3RxPsEmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(X,y, test_size=0.25,stratify=y,random_state=42)"
      ],
      "metadata": {
        "id": "7q2iNhbqrfqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"training images: \")\n",
        "print(x_train.shape,y_train.shape)\n",
        "print('-'*50)\n",
        "print(\"testing images: \")\n",
        "print(x_test.shape,y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hk-D9oLrftF",
        "outputId": "c68f22b3-badc-4fea-c53e-3005b5e322b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training images: \n",
            "(2193, 224, 224, 3) (2193,)\n",
            "--------------------------------------------------\n",
            "testing images: \n",
            "(732, 224, 224, 3) (732,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scalling the Data values so that the range is between 0-1 to avoid overfitting and avoid giving weights imbalanced importance values :**"
      ],
      "metadata": {
        "id": "h7UBIKXouMlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#take the first train image and scale them\n",
        "x_train_scaled=x_train/255"
      ],
      "metadata": {
        "id": "4Cen0GZZ3lNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#take the first 3000 test image and scale them\n",
        "x_test_scaled_img=x_test/255"
      ],
      "metadata": {
        "id": "W-AC7tU84MOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_scaled.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QixK6UUD6byJ",
        "outputId": "2bf48ac9-8d2a-43de-bcd4-546dae8e2cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2193, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Creation : "
      ],
      "metadata": {
        "id": "5qC89AD93UXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "metadata": {
        "id": "gAfK4doo3TyH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobile_net_model='https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4'\n",
        "#import mobile net model with input shape same for our photos and trainable = false not trained on the last layer\n",
        "pretrained_model=hub.KerasLayer(mobile_net_model,input_shape=(224,224,3),trainable=False)"
      ],
      "metadata": {
        "id": "JkPjbzBD3T0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#specify the number of classes and the shape of the model\n",
        "number_of_classes=6\n",
        "\n",
        "model=tf.keras.Sequential([\n",
        "    pretrained_model,\n",
        "    #Output layer\n",
        "    tf.keras.layers.Dense(number_of_classes)\n",
        "\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "OZC8mlxJ3T3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91431676-be30-4046-d359-1fb5782d9744"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 6)                 7686      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,265,670\n",
            "Trainable params: 7,686\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import metrics\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics = ['acc']\n",
        ")\n"
      ],
      "metadata": {
        "id": "X7jwUfxA3T6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training :"
      ],
      "metadata": {
        "id": "srmwUzF-Mfgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train_scaled,y_train,epochs=5)"
      ],
      "metadata": {
        "id": "UifMIEdhrf0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eceb4602-3102-4b4f-e2f8-d7f643458577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "69/69 [==============================] - 61s 824ms/step - loss: 0.5652 - acc: 0.7939\n",
            "Epoch 2/5\n",
            "69/69 [==============================] - 57s 823ms/step - loss: 0.2277 - acc: 0.9311\n",
            "Epoch 3/5\n",
            "69/69 [==============================] - 59s 856ms/step - loss: 0.1742 - acc: 0.9489\n",
            "Epoch 4/5\n",
            "69/69 [==============================] - 57s 823ms/step - loss: 0.1414 - acc: 0.9594\n",
            "Epoch 5/5\n",
            "69/69 [==============================] - 57s 823ms/step - loss: 0.1217 - acc: 0.9676\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f292d1e35e0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "1Flvz9oeMkNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score,acc=model.evaluate(x_test_scaled_img,y_test)\n",
        "\n",
        "print('Test score = ',score,\"Accuracy Score = \",acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5WnLcKeBArY",
        "outputId": "252e7c49-3f7f-4a3d-900c-6264846e5aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 20s 829ms/step - loss: 0.2004 - acc: 0.9385\n",
            "Test score =  0.20035232603549957 Accuracy Score =  0.938524603843689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat=model.predict(x_test_scaled_img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytcCbHecJLtf",
        "outputId": "403fa216-6464-4fd0-a3ee-3cd77ed1599a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 26s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Cm=confusion_matrix(y_test,np.argmax(y_hat, axis=1))\n",
        "print('Comfusion Matrix ')\n",
        "print('-'*50)\n",
        "print (pd.DataFrame(Cm, columns=['dogs','cats','horses','cows'],index=['dogs','cats','horses','cows']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NLNmN_IcI1xA",
        "outputId": "f0dcbfba-644b-4444-d530-3a0edae7783a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comfusion Matrix \n",
            "--------------------------------------------------\n",
            "        dogs  cats  horses  cows\n",
            "dogs     179     4       4     2\n",
            "cats       6   171       2     1\n",
            "horses     3     0     165    16\n",
            "cows       3     0       4   172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GG EZ"
      ],
      "metadata": {
        "id": "AiHqz_jhI1zv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}